# combined_inference.py
# å–®éšæ®µæµç¨‹ï¼š
#   ConvNeXt å½±åƒåˆ†é¡ â†’ RAGï¼ˆMilvusï¼‰â†’ DeepSeek LLM å ±å‘Š

import json
from typing import Dict, Any, List, Optional

import requests

from lesion_model import predict_lesion
from rag_milvus import search_knowledge

# Ollama ä¼ºæœå™¨ï¼ˆDeepSeek-R1 14Bï¼‰
OLLAMA_URL = "http://127.0.0.1:11434/api/generate"
LLM_MODEL = "deepseek-r1:14b"


# ---------------------------
# é¢¨éšªè©•ä¼°ï¼ˆä¾ç›®å‰ 8 é¡ä¸­æ–‡æ¨™ç±¤ï¼‰
# ---------------------------
def compute_risk_flag(top1_label: str, conf: float) -> str:
    """
    ä¾ç…§åˆ†é¡çµæœçµ¦ä¸€å€‹å¤§æ¦‚çš„é¢¨éšªç­‰ç´šå­—ä¸²ã€‚
    ä½ ä¹‹å¾Œè¦ºå¾—ä¸åˆç†å¯ä»¥å†èª¿é€™è£¡å°±å¥½ã€‚
    """
    malignant = {"åŸºåº•ç´°èƒç™Œ", "é±—ç‹€ç´°èƒç™Œ"}
    pre_malignant = {"å…‰åŒ–æ€§è§’åŒ–"}

    if top1_label in malignant and conf >= 0.50:
        return "ğŸ”´ å½±åƒé¡¯ç¤ºç–‘ä¼¼çš®è†šæƒ¡æ€§è…«ç˜¤ï¼Œå»ºè­°å„˜é€Ÿå°±é†«ï¼Œç”±çš®è†šç§‘é†«å¸«é¢è¨ºç¢ºèªã€‚"
    if top1_label in pre_malignant and conf >= 0.50:
        return "ğŸŸ¡ å½±åƒé¡¯ç¤ºå¯èƒ½ç‚ºç™Œå‰ç—…è®Šï¼Œå»ºè­°å„˜æ—©å®‰æ’çš®è†šç§‘é–€è¨ºè¿½è¹¤ã€‚"
    return "ğŸŸ¢ ç›®å‰åˆ†é¡å¤šåå‘è‰¯æ€§ç—…ç¶ï¼Œä½†ä»å»ºè­°ä¾å¯¦éš›ç—‡ç‹€èˆ‡é†«å¸«è©•ä¼°ç‚ºä¸»ã€‚"


# ---------------------------
# LLM å ±å‘Šç”¨çš„ Prompt
# ---------------------------
def build_report_prompt(
    lesion: Dict[str, Any],
    rag_info: List[Dict[str, Any]],
    risk_flag: str,
) -> str:
    top1 = lesion.get("top1", {})
    top3 = lesion.get("top3", [])

    label = top1.get("label", "æœªçŸ¥ç—…ç¶")
    conf = float(top1.get("confidence", 0.0)) * 100.0

    sb: List[str] = []

    sb.append("ä½ æ˜¯ä¸€å¥—å”åŠ©å°ç£çš®è†šç§‘é–€è¨ºçš„è‡¨åºŠæ±ºç­–è¼”åŠ©ç³»çµ±ã€‚")
    sb.append("ä½ åªèƒ½æ ¹æ“šæˆ‘æä¾›çš„ RAG é†«å­¸å…§å®¹èˆ‡æ¨¡å‹è¼¸å‡ºé€²è¡Œèªªæ˜ï¼Œä¸å¯ä»¥è‡ªè¡Œå»¶ä¼¸é¡å¤–é†«å­¸çŸ¥è­˜ã€‚")
    sb.append("è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œèªæ°£ä¸­ç«‹ä¸”æ˜“æ‡‚ï¼Œå›ç­”çµ¦ä¸€èˆ¬æ°‘çœ¾é–±è®€ã€‚")
    sb.append("")
    sb.append("=== å½±åƒ AI åˆ†é¡çµæœï¼ˆåƒ…ä¾›åƒè€ƒï¼Œéæ­£å¼è¨ºæ–·ï¼‰ ===")
    sb.append(f"- æ¨¡å‹ä¸»è¦åˆ†é¡çµæœï¼š{label}ï¼ˆä¿¡å¿ƒç´„ {conf:.1f}%ï¼‰")
    if top3:
        sb.append("- Top3 å¯èƒ½çµæœï¼š")
        for i, item in enumerate(top3, start=1):
            sb.append(
                f"  {i}. {item.get('label', 'æœªçŸ¥')} "
                f"(ç´„ {float(item.get('confidence', 0.0))*100:.1f}%)"
            )
    sb.append("")
    sb.append("=== é¢¨éšªæç¤ºï¼ˆç³»çµ±å…§è¦å‰‡è©•ä¼°ï¼‰ ===")
    sb.append(risk_flag)
    sb.append("")
    sb.append("=== å¯ä½¿ç”¨çš„é†«å­¸çŸ¥è­˜ï¼ˆRAG æŸ¥è©¢çµæœï¼‰ ===")

    if not rag_info:
        sb.append("ï¼ˆç›®å‰è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ°èˆ‡æ­¤ç—…åç›¸ç¬¦çš„æ¢ç›®ï¼Œè«‹ä½ æ˜ç¢ºèªªæ˜è³‡è¨Šæœ‰é™ã€‚ï¼‰")
    else:
        for i, item in enumerate(rag_info, start=1):
            title = item.get("title") or "æœªå‘½åæ¢ç›®"
            content = item.get("content") or ""
            url = item.get("url") or ""
            sb.append(f"ã€è³‡æ–™ {i}ï¼š{title}ã€‘")
            if url:
                sb.append(f"ä¾†æºé€£çµï¼š{url}")
            sb.append(content)
            sb.append("")

    sb.append("")
    sb.append("=== å›è¦†è¦æ±‚ ===")
    sb.append("è«‹ä¾ç…§ä¸‹é¢çµæ§‹ï¼Œæ•´ç†ä¸€ä»½çµ¦æ°‘çœ¾çœ‹çš„èªªæ˜ï¼š")
    sb.append("ä¸€ã€æ­¤é¡çš®è†šç—…ç¶çš„ç°¡ä»‹ï¼ˆä¾ç…§ RAG å…§å®¹ï¼Œä¸è¦åŠ å…¥é¡å¤–çŸ¥è­˜ï¼‰ã€‚")
    sb.append("äºŒã€å¸¸è¦‹çš„ç—‡ç‹€èˆ‡å¤–è§€ç‰¹å¾µï¼ˆç›¡é‡å°æ‡‰ RAG å…§å®¹ï¼‰ã€‚")
    sb.append("ä¸‰ã€å¯èƒ½çš„é¢¨éšªèˆ‡éœ€è¦æ³¨æ„çš„æƒ…æ³ï¼ˆçµåˆä¸Šè¿°é¢¨éšªæç¤ºèˆ‡ RAGï¼‰ã€‚")
    sb.append("å››ã€å±…å®¶ç…§è­·èˆ‡æ—¥å¸¸æ³¨æ„äº‹é …ï¼ˆæ¸…æ½”ã€ä¿æ¿•ã€é¿å…åˆºæ¿€ç­‰ï¼Œä¸€æ¨£è¦ä»¥ RAG å…§å®¹ç‚ºä¸»ï¼‰ã€‚")
    sb.append("äº”ã€ä½•æ™‚æ‡‰è©²å°±é†«æˆ–å›è¨ºï¼Œç‰¹åˆ¥æ˜¯å“ªäº›è­¦è¨Šéœ€è¦å„˜é€Ÿå°±é†«ã€‚")
    sb.append("")
    sb.append("è«‹ä»¥æ¢åˆ—èˆ‡çŸ­æ®µè½æ•´ç†ï¼Œè®“ä¸€èˆ¬æ°‘çœ¾å¯ä»¥çœ‹æ‡‚ã€‚")

    return "\n".join(sb)


# ---------------------------
# å‘¼å« Ollama LLM
# ---------------------------
def call_llm(prompt: str) -> str:
    payload = {
        "model": LLM_MODEL,
        "prompt": prompt,
        "stream": False,
        "temperature": 0.7,
    }
    resp = requests.post(OLLAMA_URL, json=payload, timeout=300)
    resp.raise_for_status()
    data = resp.json()
    return data.get("response", "")


# ---------------------------
# ä¸»æµç¨‹ï¼šå½±åƒ â†’ RAG â†’ LLM
# ---------------------------
def predict_combined(
    image_path: str,
    survey: Optional[Dict[str, Any]] = None,  # ç¾åœ¨ä¸å†ä½¿ç”¨å•å·ï¼Œä½†ä¿ç•™åƒæ•¸é¿å…çˆ†æ‰
) -> Dict[str, Any]:
    try:
        # 1ï¸âƒ£ ConvNeXt å½±åƒåˆ†é¡
        lesion = predict_lesion(image_path)
        top1 = lesion.get("top1", {})
        top1_label = top1.get("label", "æœªçŸ¥")
        top1_conf = float(top1.get("confidence", 0.0))

        # 2ï¸âƒ£ é¢¨éšªç°¡æ˜“è©•ä¼°
        risk_flag = compute_risk_flag(top1_label, top1_conf)

        # 3ï¸âƒ£ RAGï¼šç”¨ top1 label å» DermNet / Milvus æœå°‹
        rag_info: List[Dict[str, Any]] = search_knowledge(top1_label, top_k=5)

        # 4ï¸âƒ£ å»ºç«‹ LLM Prompt + å‘¼å« DeepSeek
        prompt = build_report_prompt(lesion, rag_info, risk_flag)

        try:
            final_text = call_llm(prompt)
        except Exception as llm_err:
            print("âš ï¸ LLM å‘¼å«å¤±æ•—ï¼š", llm_err)
            final_text = "ç³»çµ±åœ¨ç”¢ç”Ÿèªªæ˜æ–‡å­—æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œä½†å½±åƒåˆ†é¡çµæœä»å¯ä¾›é†«å¸«åƒè€ƒã€‚"

        # 5ï¸âƒ£ ç°¡çŸ­ summaryï¼ˆæ–¹ä¾¿ log / debugï¼‰
        top3_labels = [x.get("label", "") for x in lesion.get("top3", [])]
        summary = (
            f"AI ä¸»è¦åˆ†é¡çµæœï¼š{top1_label}ï¼ˆç´„ {top1_conf*100:.1f}%ï¼‰ï¼›"
            f"Top3 ä¾åºç‚ºï¼š{', '.join(top3_labels) or 'ç„¡'}ã€‚"
        )

        return {
            "lesion": lesion,              # å½±åƒæ¨¡å‹åŸå§‹çµæœ
            "rag": rag_info,               # RAG å–å›çš„é†«å­¸å…§å®¹
            "risk_flag": risk_flag,        # é¢¨éšªæ–‡å­—
            "summary": summary,            # ç°¡çŸ­æ‘˜è¦
            "final_top1": top1_label,      # çµ¦å‰ç«¯ç”¨çš„ä¸»è¦çµæœ
            "final_text": final_text,      # LLM å ±å‘Š
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "error": str(e),
            "summary": "âš ï¸ æ¨è«–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤",
            "rag": [],
            "final_top1": "ç„¡è³‡æ–™",
            "final_text": "ç³»çµ±åœ¨åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–æ´½ç³»çµ±ç®¡ç†è€…ã€‚",
        }
